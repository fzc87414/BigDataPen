
1、准备虚拟机，所用版本VMware-workstation-full-10.0.3-1895310
2、安装CentOS，所用版本CentOS-6.5-i386-bin-DVD1
	网络适配器：桥接模式
3、关selinux 和 iptables
	[root@base ~]# vi /etc/selinux/config
	[root@base ~]# chkconfig iptables off
4、安装JDK(jdk-6u45-linux-i586.bin)配置环境/etc/profile
	干掉系统自带openjdk：
	rpm -qa | grep java
	改root用户
	rpm -e --nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.i686
	java -version
	rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.i686
	vi /etc/profile
	source /etc/profile

	安装：
	cd /home/hadoop
	./jdk-6u45-linux-i586.bin
	配环境:
	vi /etc/profile
	
	export JAVA_HOME=/usr/java/jdk1.6.0_45
	export JRE_HOME=$JAVA_HOME/jre
	export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
	export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib
	
	.bash_logout 配置用户登录出去执行什么
	.bash_profile 配置用户特殊的profile
	.bashrc 配置bash专用的(bash是一种shell linux 可以有很多种shell 比如C shell 就是C语言风格的shell 如果用C shell 这个文件就没用了)
5、配置/etc/sysconfig/network-scripts/ifcfg-eth0
	DEVICE=eth0
	#复制的虚拟机需要改这个硬件地址，最好在外面重新生成然后修改
	HWADDR=00:0C:29:01:FF:78
	TYPE=Ethernet
	UUID=0ca7c5f6-daff-4f43-ae2b-d4155e687d60
	#开机启动网卡
	ONBOOT=yes
	NM_CONTROLLED=yes
	#使用静态IP配置
	BOOTPROTO=dhcp
	
	有外网测试安装setuptool
	yum -y install setuptool
	没有外网 ifconfig 看有否有 eth0 并且eth0 有IP 能ping通其他的虚拟机
6、修改/etc/hosts
	192.168.36.130 master
	192.168.36.131 slave1
	192.168.36.132 slave2
	192.168.36.133 slave3
7、修改 /etc/security/limits.conf 最后加 配置最大线程和文件打开数
	* - nproc 65535
	* - nofile 65535

8、确保创建了 hadoop 这个用户 实现无密码验证登录
	su - hadoop
	mkdir ~/.ssh
	cd ~/.ssh
	ssh-keygen -t rsa -P ' '
	cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

	chmod 600 authorized_keys

9、配置.ssh权限防止没权限读取ssh的秘钥
	***一定要使用hadoop用户执行不能root代劳***
	chown -R hadoop:hadoop /home/hadoop
	chmod 700 /home/hadoop
	chmod 700 /home/hadoop/.ssh
	chmod 644 /home/hadoop/.ssh/authorized_keys
	chmod 600 /home/hadoop/.ssh/id_rsa
10、安装hadoop
	hadoop 1.0.4 传到 虚拟机 放到 /home/hadoop 目录下
	解压：
	tar -vxzf hadoop-1.0.4.tar.gz
	修改解压后的目录名(mv 是移动文件 相当于改名)
	mv hadoop-1.0.4 hadoop
	
	mkdir ~/hadoop/data
	mkdir ~/hadoop/tmp
	chmod 755 ~/hadoop/data
	chmod 755 ~/hadoop/tmp

11、配置hadoop用户目录下的 ~/.bash_profile
	将以下内容编辑到文本末尾：
	export HADOOP_HOME=/home/hadoop/hadoop
	export PATH=$PATH:$HADOOP_HOME/bin
12、统一修改hadoop用户conf目录(~/hadoop/conf)下的各种配置文件
	修改配置文件hadoop-env.sh
	搜索到JAVA_HOME所在行，然后将默认的“#”去掉，也就是打开注释，然后如下配置：
	export JAVA_HOME=/usr/java/jdk1.6.0_45

	修改配置文件 core-site.xml
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<!-- Put site-specific property overrides in this file. -->
	<configuration>
	 <property>
		  <name>fs.default.name</name>
		  <value>hdfs://master:9000</value>
	 </property>
	</configuration>

	修改配置文件 hdfs-site.xml
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<!-- Put site-specific property overrides in this file. -->
	<configuration>
	 <property>  
	  <name>dfs.replication</name>
	  <value>3</value>
	 </property>            
	 <property>  
	   <name>dfs.name.dir</name>  
	   <value>/home/hadoop/hadoop/namenode/</value>  
	  </property> 
	  <property>  
	   <name>dfs.data.dir</name>  
	   <value>/home/hadoop/hadoop/data/</value>  
	  </property>               
	  <property>  
		<name>hadoop.tmp.dir</name>  
		<value>/home/hadoop/hadoop/tmp/</value>  
	  </property>
	  <property>
	   <name>dfs.permissions</name>
	   <value>false</value>
	  </property>
	</configuration>

	修改配置文件 mapred-site.xml
	<?xml version="1.0"?>
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	<!-- Put site-specific property overrides in this file. -->
	<configuration>
	 <property>  
	   <name>mapred.job.tracker</name>  
	   <value>master:9001</value>  
	 </property>
	 <property>  
	   <name>mapred.tasktracker.map.tasks.maximum</name>  
	   <value>2</value>  
	 </property>                  
	 <property>  
		<name>mapred.tasktracker.reduce.tasks.maximum</name>  
		<value>2</value>  
	 </property>  
	</configuration>

	修改配置文件 masters
	配置如下：
	master

	修改配置文件 slaves
	配置如下：
	slave1
	slave2
13、复制4份虚拟机 并配置静态IP
	vm_master 主机ip
	vm_slave1 从机1ip
	vm_slave2 从机2ip

	hadoop namenode -format
	启动hadoop：
	start-all.sh
	启动后使用jps命令查看：
	NN上：
	jps
	namenode 1002
	secondarynamenode 1011
	jobtracker 1012
	DN上：
	jps
	datanode 2
	tasktracker 10
	然后通过http://master:50070和http://master:50030查看监控界面。
	桥接模式下可以连接外网查看



	hadoop logs中
	查看日志：
		hadoop-hadoop-namenode-master.log
	删除所有日志：
	rm -rf hadoop-hadoop-*

	hadoop namenode -format

	退出安全模式：
	hadoop dfsadmin -safemode leave
14、配置hbase：
	解压：
	tar hbase-0.94.6.tar.gz
	修改文件夹名字为hbase
	********
	配置环境变量：
	切换到root
	vi /etc/profile
	打开vi编辑器，添加以下内容到末尾
	export HBASE_HOME=/home/hadoop/hbase
	export PATH=$PATH:$HBASE_HOME/bin
	
	修改hbase配置文件
	退回hadoop用户：
	cd ~/hbase/conf
	vi hbase-env.sh
	打开vi编辑器，解封修改JAVA_HOME添加以下内容：
	export JAVA_HOME=/home/hadoop/jdk1.6.0_45
	export HBASE_CLASSPATH=/home/hadoop/hbase/conf
	export HBASE_MANAGES_ZK=true
	
	修改hbase-site.sh
	打开vi编辑器，配置如下：
	<configuration>
		//配置主机地址
		<property>
			<name>hbase.master</name>
			<value>master:60000</value>
		</property>
		//配置时间差
		<property>
			<name>hbase.master.maxclockskew</name>
			<value>180000</value>
		</property>
		//数据存在HDFS上
		<property>
			<name>hbase.rootdir</name>
			<value>hdfs://master:9000/hbase</value>
		</property>
		<property>
			<name>hbase.cluster.distributed</name>
			<value>true</value>
		</property>
		//配置从节点
		<property>
			<name>hbase.zookeeper.quorum</name>
			<value>slave1,slave2,slave3</value>
		</property>
		<property>
			<name>hbase.zookeeper.property,datadir</name>
			<value>/home/${user.name}/tmp/zookeeper</value>
		</property>
	</configuratuon> 
	通过vi工具修改配置文件reginservers
	vi reginservers
	配置如下：
	slave1
	slave2 
	slave3
	
	用scp命令将hbase文件夹拷贝给其他机器
	eg：scp -r /home/hadoop/hbase  hadoop@192.168.24.132:/home/hadoop
	
	启动hbase集群，进入监控页面查看
	首先，必须保证hadoop是启动状态的
	启动hbase：
	start-hbase.sh
	
	关闭的时候先stop-hbase.sh然后stop-all.sh

        解压缩zookeeper tar包并重新命名
	tar -zxvf zooker-3.4.5.tar.gz
	mv zookeeper-3.4.5  zoookeeper

	切换到root下编辑环境变量
	vi /etc/profile
	export ZOOKEEPER_HOME=/home/hadoop/zookeeper
	export PATH=$PATH:$ZOOKEEPER-HOME/bin
	保存
	/wq
	退回到普通用户
	exit
	创建data和log来存放数据和日志

	mkdir /home/hadoop/zookeeper/data
	chmod 755 /home/hadoop/zookeeper/data
	mkdir /home/hadoop/zookeeper/log
	chmod 755 /home/hadoop/zookeeper/log

	在data陌路下面新建myid内容为1（zookeeper01为1，zookeeper02为2）
	其余两个zookeeper节点一样
	
	复制/home/hadoop/zooker/conf/zoo_sample.cfg文件为zoo.cfg
	并修改配置
	cp zoo_sample.cfg zoo.cfg
	修改
	vi zoo.cfg

	dataDir=home/hadoop/zookeeper/data
	dataLogDir=/home/hadoop/zookeeper/log
	server.1=master:2888:3888
	server.2=slave1:2888:3888
	server.3=slave2:2888:3888
	wq保存
	一个个启动节点
	zkServer.sh start
	3个节点都启动后使用命令查看各自状态
	zkServer.sh sstatus
	其中只有一个为leader，其他为flower就算成功
